\section{Algorithm for block diagonalization}

\subsection{Problem statement}

Pymablock finds a series of the unitary transformation $\mathcal{U}$ (we use
calligraphic letters to denote series) that block-diagonalizes the Hamiltonian
%
\begin{align}
\label{hamiltonian}
\mathcal{H} = H_0 + \mathcal{H}',\quad H_0 = \begin{pmatrix}
H_0^{AA} & 0\\
0 & H_0^{BB}
\end{pmatrix},
\end{align}
%
with $\mathcal{H}'$ containing an arbitrary number and orders of perturbations.
The series here may be multivariate, and they represent sums of the form
%
\begin{align}
\mathcal{A} = \sum_{n_1=0}^\infty \sum_{n_2=0}^\infty \cdots \sum_{n_k=0}^\infty \lambda_1^{n_1} \lambda_2^{n_2} \cdots \lambda_k^{n_k} A_{n_1, n_2, \ldots, n_k},
\end{align}
%
where $\lambda_i$ are the perturbation parameters and $A_{n_1, n_2, \ldots,
n_k}$ are linear operators.
%
The problem statement, therefore, is finding $\mathcal{U}$ and
$\tilde{\mathcal{H}}$ such that:
%
\begin{align}
\label{eq:problem_definition}
\tilde{\mathcal{H}} = \mathcal{U}^\dagger \mathcal{H} \mathcal{U},\quad \tilde{\mathcal{H}}^{AB} = 0,\quad \mathcal{U}^\dagger \mathcal{U} = 1,
\end{align}
%
where series multiply according to the Cauchy product:
%
$$
\mathcal{C} = \mathcal{A}\mathcal{B} \Leftrightarrow C_\mathbf{n} = \sum_{\mathbf{m} + \mathbf{p} = \mathbf{n}} A_\mathbf{m} B_\mathbf{p}.
$$
%
This product is the most expensive operation in perturbation theory, because it
involves a large number of multiplications between potentially large matrices.
For example, evaluating $\mathbf{n}$-th order of $\mathcal{C}$ requires
$\sim\prod_i n_i = N$ multiplications of the series elements.
A direct computation of all the possible index combinations in a product
between three series $\mathcal{A}\mathcal{B}\mathcal{C}$ would have a higher
cost $\sim N^2$, however if we use associativity of the product and compute
this as $(\mathcal{A}\mathcal{B})\mathcal{C}$, then the scaling of the cost
stays $\sim N$.

There are many ways to solve this problem that give identical expressions for
$\mathcal{U}$ and $\tilde{\mathcal{H}}$.
We are searching for a procedure that satisfies two additional constraints:
%
\begin{itemize}
    \item It has the same complexity scaling as a Cauchy product.
    \item It does not require multiplications by $H_0$.
    This is because in perturbation theory, $n$-th order  corrections to
    $\tilde{\mathcal{H}}$ carry $n$ energy denominators $1/(E_i - E_j)$.
    Therefore, any additional multiplications by $H_0$ must cancel with
    additional energy denominators.
    Multiplying by $H_0$ is therefore unnecessary work, and it gives longer
    intermediate expressions.
\end{itemize}
%
The goal of our algorithm is thus to be efficient and to produce compact
results that do not require further simplifications.
\subsection{Existing solutions}
\co{Pymablock's algorithm does not use the Schrieffer-Wolff transformation,
because the former is inefficient.}
A common approach to construct effective Hamiltonians is to use a
Schrieffer-Wolff transformation:
%
\begin{align}
\tilde{\mathcal{H}} = e^\mathcal{S} &\mathcal{H} e^{-\mathcal{S}}, \\
e^{\mathcal{S}} = 1 + \mathcal{S} + \frac{1}{2!} \mathcal{S} \mathcal{S}
+ &\frac{1}{3!} \mathcal{S} \mathcal{S} \mathcal{S} + \cdots,
\end{align}
%
where $\mathcal{S} = \sum_n S_n$ is an antihermitian polynomial series in the
perturbative parameter, making $e^\mathcal{S}$ a unitary transformation.
In this approach, $\mathcal{S}$ is found by ensuring unitarity and the block
diagonalization of the Hamiltonian to every order, a procedure that amounts to
solving a recursive equation whose terms are nested commutators between series.
Moreover, the transformed Hamiltonian is also given by a series of nested
commutators
%
\begin{equation}
\tilde{\mathcal{H}} = \sum_{j=0}^\infty \frac{1}{j!} \Big [\mathcal{H}, \sum_{n=0}^{\infty} S_n \Big ]^{(j)},
\end{equation}
%
a computationally expensive expression because it requires computing
exponentially many matrix products.
This expression also requires truncating the series at the same order
to which $\mathcal{S}$ is computed, which is a waste of computational resources.
Finally, generalizing the Schrieffer-Wolff transformation to multiple
perturbations is only straightforward if the perturbations are bundled
together.
However, this makes it impossible to request individual order combinations
of the perturbations, making it necessary to compute more terms than needed.

\co{There are algorithms that use different parametrizations for U a
difference that is crucial for efficiency, even though the results are
equivalent.}
The algorithm used to block diagonalize a Hamiltonian perturbatively is,
however, not unique.
Alternative parametrizations of the unitary transformation $\mathcal{U}$
require solving unitarity and block diagonalization conditions too, but
give rise to a different recursive procedure for the series elements.
For example, using hyperbolic functions
%
\begin{gather}
\mathcal{U} = \cosh{\mathcal{G}} + \sinh{\mathcal{G}}, \quad
\mathcal{G} = \sum_{i=0}^{\infty} G_i,
\end{gather}
%
leads to recursive equations for $G_i$ that use Bernoulli numbers as
prefactors for contributions from lower order terms \cite{Shavitt_1980},
making the algorithm inefficient.
On the other hand, using a polynomial series directly
%
\begin{align}
\mathcal{U} &= \sum_{i=0}^{\infty} U_i,
\end{align}
%
gives rise to a recursive equation for $U_i$ that is free from any additional
coefficients
\cite{Van_Vleck_1929}, \cite{Lowdin_1962}
\cite{Klein_1974}, \cite{Suzuki_1983}.
This choice, however, results in an expression for $\tilde{\mathcal{H}}$ whose
terms include products by $H_0$, and therefore requires additional
simplifications.

\co{The existing algorithms with linear scaling are not suitable for the
construction of an effective Hamiltonian.}
Despite the conceptual equivalence of the algorithms and the agreement of their
results, there is a crucial difference in their computational efficiency: a
Schrieffer-Wolff transformation has an exponential scaling with the
perturbative order, but it can be reduced.
C. Bloch's perturbation theory \cite{Bloch_1958}, for example,
aims to find a similarity transform that brings the Hamiltonian to a
block-triangular form, losing its Hermiticity and orhogonality properties.
The iterative procedure to find the similarity transform requires computing
fewer expressions for the series elements than the Schrieffer-Wolff
transformation \cite{Bravyi_2011}, and the effective Hamiltonian is more
compact.
However, the algorithm is only useful to obtain the spectrum of the low energy
subspace, not its wavefunctions.
Reference \cite{Li_2022}, for example, introduces an
algorithm with linear scaling for diagonalization of a single state by
reformulating the recursive steps of the Schrieffer-Wolff transformation.
Block diagonalization of a Hamiltonian, however, recovers the exponential
scaling.
Another approach with linear scaling is that of density matrix perturbation
theory \cite{McWeeny_1962,McWeeny_1968,Truflandier_2020}, in which the
density matrix of a single-particle system is also a power series with
respect to a perturbative parameter:
%
\begin{align}
  \mathcal{D} = \sum_{i=0}^{\infty} D_i.
\end{align}
%
The elements of the series are found by solving two recursive conditions,
$\mathcal{D}^2 = \mathcal{D}$ and $[\mathcal{H}, \mathcal{D}]=0$.
This approach, however, does not provide an effective Hamiltonian, and even
though it has a linear scaling, it deals with the entire Hilbert space, not
only the low energy subspace.
We thus identify the need for an algorithm that combines linear scaling with
the ability to construct an effective Hamiltonian.

\subsection{Our solution}

To find $\mathcal{U}$, let us separate it into an identity and $\mathcal{U}' =
\mathcal{W} + \mathcal{V}$:
%
\begin{align}
\label{eq:U}
\mathcal{U} = 1 + \mathcal{U}' = 1 + \mathcal{W} + \mathcal{V},\quad \mathcal{W}^\dagger = \mathcal{W},\quad \mathcal{V}^\dagger = -\mathcal{V}.
\end{align}
%
First, we use the unitarity condition
$\mathcal{U}^\dagger \mathcal{U} = 1$ by substituting $\mathcal{U}'$ into it
and obtain
%
\begin{align}
\label{eq:W}
\mathcal{W} &= \frac{1}{2}(\mathcal{U}'^\dagger + \mathcal{U}') \nonumber \\
  &= \frac{1}{2} \Big[(1 + \mathcal{U}'^\dagger)(1+\mathcal{U}') - 1 - \mathcal{U}'^\dagger \mathcal{U}' \Big] \nonumber \\
  &= -\frac{1}{2} \mathcal{U}'^\dagger \mathcal{U}'.
\end{align}
%
Because $\mathcal{U}'$ has no $0$-th order term, $(\mathcal{U}'^\dagger
\mathcal{U}')_\mathbf{n}$ does not depend on the $\mathbf{n}$-th order of
$\mathcal{U}'$ nor $\mathcal{W}$.
More generally, a Cauchy product $\mathcal{A}\mathcal{B}$ where $\mathcal{A}$
and $\mathcal{B}$ have no $0$-th order terms depends on $\mathcal{A}_1, \ldots,
\mathcal{A}_{n-1}$ and $\mathcal{B}_1, \ldots, \mathcal{B}_{n-1}$.
This allows us to use Cauchy products to define recurrence relations, which
we apply throughout the algorithm.
Therefore, we compute $\mathcal{W}$ as a Cauchy product of $\mathcal{U}'$ with
itself \footnotemark[1].

\footnotetext[1]{
Using the definition of $\mathcal{W}$ as the Hermitian part of $\mathcal{U}'$,
and the unitarity condition:
%
$$
2\mathcal{W}
= \mathcal{U}' + \mathcal{U}'^\dagger
= -\mathcal{U}'^\dagger \mathcal{U}'
= -\mathcal{W}^2 + \mathcal{V}^2.
$$
%
we see that we could alternatively define $\mathcal{W}$ as a Taylor series in
$\mathcal{V}$:
%
$$
\mathcal{W} = \sqrt{1 + \mathcal{V}^2} - 1 \equiv f(\mathcal{V}) \equiv \sum_n a_n \mathcal{V}^{2n},
$$
%
however the scaling of such a Cauchy product becomes slower if we need to
compute a Taylor expansion of a series:
%
$$
f(\mathcal{A}) = \sum_{n=0}^\infty a_n \mathcal{A}^n.
$$
%
However, evaluating a Taylor expansion of a given series has a higher scaling
of complexity.
A direct computation of all possible products of terms would require $\sim \exp
N$ multiplications.
We improve on this by defining a new series as $\mathcal{A}^{n+1} =
\mathcal{A}\mathcal{A}^{n}$ and reusing the previously computed results, which
brings these costs down to $\sim N^2$.
Using the Taylor expansion approach is therefore both more complicated and more
computationally expensive than the recurrent definition in \ref{eq:W}.
}

To compute $\mathcal{U}'$ we also need to find $\mathcal{V}$, which is defined
by the requirement $\tilde{\mathcal{H}}^{AB} = 0$.
Additionally, we constrain $\mathcal{V}$ to be block off-diagonal:
$\mathcal{V}^{AA} = \mathcal{V}^{BB} = 0$,
so that the resulting unitary transformation is equivalent to the
Schrieffer-Wolff transformation \footnotemark[2].
In turn, this means that $\mathcal{W}$ is block-diagonal and that the norm
of $\mathcal{U}'$ is minimal.

\footnotetext[2]{
\textbf{Equivalence to Schrieffer-Wolff transformation}
Both the Pymablock algorithm and the more commonly used Schrieffer-Wolff
transformation find a unitary transformation $\mathcal{U}$ such that
$\tilde{\mathcal{H}}^{AB}=0$.
They are therefore equivalent up to a gauge choice in each subspace, $A$ and
$B$.
We establish the equivalence between the two by demonstrating that this gauge
choice is the same for both algorithms.
The Schrieffer-Wolff transformation uses $\mathcal{U} = \exp \mathcal{S}$,
where $\mathcal{S} = -\mathcal{S}^\dagger$ and $\mathcal{S}^{AA} =
\mathcal{S}^{BB} = 0$.
The series $\exp\mathcal{S}$ contains all possible products of $S_n$ of all
lengths with fractional prefactors.
For every term $S_{k_1}S_{k_2}\cdots S_{k_n}$, there is a corresponding term
$S_{k_n}S_{k_{n-1}}\cdots S_{k_1}$ with the same prefactor.
If the number of $S_{k_n}$ is even, then both terms are block-diagonal since
each $S_n$ is block off-diagonal.
Because $S_n$ are anti-Hermitian, the two terms are Hermitian conjugates of each
other, and therefore their sum is Hermitian.
On the other hand, if the number of $S_{k_n}$ is odd, then the two terms are
block off-diagonal and their sum is anti-Hermitian by the same reasoning.
Therefore, just like in our algorithm, the diagonal blocks of $\exp S$ are
Hermitian, while off-diagonal blocks are anti-Hermitian.
Schrieffer-Wolff transformation produces a unique answer and satisfies the same
diagonalization requirements as our algorithm, which means that the two are
equivalent.
}

\co{We find V and the transformed Hamiltonian.}
To find $\mathcal{V}$, we need to first look at the transformed Hamiltonian:
%
\begin{align}
\tilde{\mathcal{H}} = \mathcal{U}^\dagger \mathcal{H} \mathcal{U} = H_0 +
\mathcal{U}'^\dagger H_0 + H_0 \mathcal{U}' + \mathcal{U}'^\dagger H_0
\mathcal{U}' + \mathcal{U}^\dagger\mathcal{H'}\mathcal{U},
\end{align}
%
where we used $\mathcal{U}=1+\mathcal{U}'$ and $\mathcal{H} = H_0 +
\mathcal{H'}$.
Because we want to avoid unnecessary products by $H_0$, we need to get rid of
the terms that contain it by replacing them with an alternative expression.
Our strategy is to define an auxiliary operator $\mathcal{X}$ that we can
compute without ever multiplying by $H_0$.
Like $\mathcal{U}'$, $\mathcal{X}$ needs to be defined via a recurrence
relation, which we will find later.
Because the expression above has $H_0$ multiplied by $\mathcal{U}'$ by the left
and by the right, we get rid of these terms by making sure that $H_0$
multiplies terms from one side only.
To achieve this, we choose $\mathcal{X}=\mathcal{Y}+\mathcal{Z}$ to be the commutator between
$\mathcal{U}'$ and $H_0$:
%
\begin{align}
\label{eq:XYZ}
\mathcal{X} \equiv [\mathcal{U}', H_0] = \mathcal{Y} + \mathcal{Z}, \quad
\mathcal{Y} \equiv [\mathcal{V}, H_0] = \mathcal{Y}^\dagger,\quad
\mathcal{Z} \equiv [\mathcal{W}, H_0] = -\mathcal{Z}^\dagger,
\end{align}
%
where $\mathcal{Y}$ is therefore block off-diagonal and $\mathcal{Z}$, block
diagonal.
We use $H_0 \mathcal{U}' = \mathcal{U}' H_0 -\mathcal{X}$ to move $H_0$ through
to the right and find
%
\begin{align}
\label{eq:H_tilde}
  \tilde{\mathcal{H}}
  &= H_0 + \mathcal{U}'^\dagger H_0 + (H_0 \mathcal{U}') + \mathcal{U}'^\dagger H_0
  \mathcal{U}' + \mathcal{U}^\dagger(\mathcal{H'}\mathcal{U}) \nonumber
  \\
  &= H_0 + \mathcal{U}'^\dagger H_0 + \mathcal{U}'H_0 - \mathcal{X} + \mathcal{U}'^\dagger (\mathcal{U}' H_0 - \mathcal{X}) + \mathcal{U}^\dagger\mathcal{H'}\mathcal{U} \nonumber \\
  &= H_0 + (\mathcal{U}'^\dagger + \mathcal{U}' + \mathcal{U}'^\dagger \mathcal{U}')H_0 - \mathcal{X} - \mathcal{U}'^\dagger \mathcal{X} + \mathcal{U}^\dagger\mathcal{H'}\mathcal{U} \nonumber \\
  &= H_0 - \mathcal{X} - \mathcal{U}'^\dagger \mathcal{X} + \mathcal{U}^\dagger\mathcal{H'}\mathcal{U},
\end{align}
%
where the terms multiplied by $H_0$ cancel by unitarity.

The transformed Hamiltonian does not contain products by $H_0$ anymore, but it
does depend on $\mathcal{X}$, an auxiliary operator whose recurrent definition
we do not know yet.
To find it, we first focus on its anti-Hermitian part, $\mathcal{Z}$.
Since recurrence relations are expressions whose right hand side contains
Cauchy products between series, we need to find a way to make a product appear.
We do so by using the unitarity condition $\mathcal{U}'^\dagger + \mathcal{U}' =
-\mathcal{U}'^\dagger \mathcal{U}'$ to rewrite $\mathcal{Z}$:
%
\begin{align}
\label{eq:Z}
\mathcal{Z}
&= \frac{1}{2} (\mathcal{X} - \mathcal{X}^{\dagger}) \nonumber \\
&= \frac{1}{2}\Big[ (\mathcal{U}' + \mathcal{U}'^{\dagger}) H_0 - H_0 (\mathcal{U}' + \mathcal{U}'^{\dagger}) \Big] \nonumber \\
&= \frac{1}{2} \Big[ - \mathcal{U}'^{\dagger} (\mathcal{U}'H_0 - H_0 \mathcal{U}') + (\mathcal{U}'H_0 - H_0 \mathcal{U}')^{\dagger} \mathcal{U}' \Big] \nonumber \\
&= \frac{1}{2} (-\mathcal{U}'^{\dagger} \mathcal{X} + \mathcal{X}^{\dagger} \mathcal{U}').
\end{align}
%
Similar to computing $W_{\mathbf{n}}$, computing $Z_{\mathbf{n}}$ requires lower orders of
$\mathcal{X}$ and $\mathcal{U}'$, all blocks included.
This defines a recursive relation for $\mathcal{Z}$.
Then, we compute the Hermitian part of $\mathcal{X}$ by requiring that
$\tilde{\mathcal{H}}^{AB} = 0$ and find
%
\begin{align}
\label{eq:Y}
\mathcal{X}^{AB} = (\mathcal{U}^\dagger \mathcal{H}' \mathcal{U} -
\mathcal{U}'^\dagger \mathcal{X})^{AB}.
\end{align}
%
Once again, despite $\mathcal{X}$ enters the right hand side, because all the
terms lack \nth{0} order, this defines a recursive relation for $\mathcal{X}^{AB}$,
and therefore $\mathcal{Y}$.

The final part is standard: the definition of $\mathcal{Y}$ in \eqref{eq:XYZ} fixes
$\mathcal{V}$ as a solution of:
%
\begin{align}
\label{eq:sylvester}
\mathcal{V}^{AB}H_0^{BB} - H_0^{AA} \mathcal{V}^{AB} = \mathcal{Y}^{AB},
\end{align}
%
a Sylvester's equation, which we only need to solve once for every new order.
In the eigenbasis of $H_0$, the solution of Sylvester's equation is
$V^{AB}_{\mathbf{n}, ij} = Y^{AB}_{\mathbf{n}, ij}/(E_i - E_j)$, where $E_i$ are the eigenvalues of
$H_0$.
However, even if the eigenbasis of $H_0$ is not available, there are efficient
algorithms to solve Sylvester's equation, see below.

\subsection{Algorithm}

We now have the complete algorithm:
%
\begin{enumerate}
    \item Define series $\mathcal{U}'$ and $\mathcal{X}$ and make use of their block structure and Hermiticity.
    \item To define the diagonal blocks of $\mathcal{U}'$, use $\mathcal{W} = -\mathcal{U}'^\dagger\mathcal{U}'/2$.
    \item To find the off-diagonal blocks of $\mathcal{U}'$, solve Sylvester's equation $\mathcal{V}^{AB}H_0^{BB} - H_0^{AA}\mathcal{V}^{AB} = \mathcal{Y}^{AB}$.
      This requires $\mathcal{X}$.
    \item To find the diagonal blocks of $\mathcal{X}$, define $\mathcal{Z} = (-\mathcal{U}'^\dagger\mathcal{X} + \mathcal{X}^\dagger\mathcal{U}')/2$.
    \item For the off-diagonal blocks of $\mathcal{X}$, use $\mathcal{Y}^{AB} =
    (-\mathcal{U}'^\dagger\mathcal{X} +
     \mathcal{U}^\dagger\mathcal{H}'\mathcal{U})^{AB}$.
    \item  Compute the effective Hamiltonian as $\tilde{\mathcal{H}}_{\textrm{diag}} = H_0 - \mathcal{X} - \mathcal{U}'^\dagger \mathcal{X} + \mathcal{U}^\dagger\mathcal{H'}\mathcal{U}$.
\end{enumerate}

\subsection{Extra optimization: common subexpression elimination}
%
We further optimize the algorithm by reusing products that are needed in several
places.
%
Firstly, we rewrite the expressions for $\mathcal{Z}$ and $\tilde{\mathcal{H}}$
by utilizing the Hermitian conjugate of $\mathcal{U}'^\dagger \mathcal{X}$ without recomputing it:
%
\begin{gather*}
\mathcal{Z} = \frac{1}{2}[(-\mathcal{U}'^\dagger \mathcal{X})- \textrm{h.c.}],\\
\tilde{\mathcal{H}} = H_0 + \mathcal{U}^\dagger \mathcal{H}' \mathcal{U} - (\mathcal{U}'^\dagger \mathcal{X} + \textrm{h.c.}),
\end{gather*}
%
where $\textrm{h.c.}$ is the Hermitian conjugate, and $\mathcal{X}$ drops out from the diagonal blocks of $\tilde{\mathcal{H}}$ because diagonal of $\mathcal{X}$ is anti-Hermitian.
%
To compute $\mathcal{U}^\dagger \mathcal{H}' \mathcal{U}$ faster, we express it
using $\mathcal{F} \equiv \mathcal{H}'\mathcal{U}'$:
%
$$
\mathcal{U}^\dagger \mathcal{H}' \mathcal{U} = \mathcal{H}' + \mathcal{F} + \mathcal{F}^\dagger + \mathcal{U}'^\dagger \mathcal{F}.
$$
%
To further optimize the computations, we observe that some products appear both in $\mathcal{U}'^\dagger \mathcal{X}$ and $\mathcal{U}^\dagger \mathcal{H}' \mathcal{U}$.
%
To reuse these products, we separate the perturbation into diagonal and off-diagonal parts $\mathcal{H}' = \mathcal{H}'_\textrm{diag} + \mathcal{H}'_\textrm{offdiag}$.
%
We then introduce variables
%
\begin{align}
\mathcal{A} = \mathcal{H}'_\textrm{diag} \mathcal{U}', \quad
\mathcal{B} = \mathcal{H}'_\textrm{offdiag} \mathcal{U}', \quad
\mathcal{C} = \mathcal{X} - \mathcal{H}'_\textrm{offdiag}
\end{align}
%
This gives an updated expression for $\mathcal{Z}$:
%
\begin{align}
\label{eq:Z_optimized}
\mathcal{Z} = \frac{1}{2}(\mathcal{B}^\dagger - \mathcal{U}^\dagger\mathcal{C}) - \textrm{h.c.},
\end{align}
%
and more importantly for $\tilde{\mathcal{H}}$:
%
\begin{align}
\label{eq:H_tilde_optimized}
\tilde{\mathcal{H}} = H_0 + \mathcal{A} + \mathcal{A}^\dagger + (\mathcal{B} + \mathcal{B}^\dagger)/2 + \mathcal{U}'^\dagger (\mathcal{A} + \mathcal{B}) - (\mathcal{U}^\dagger \mathcal{C} + \textrm{h.c.})/2.
\end{align}

\subsection{Implicit method for large Hamiltonians}

Solving Sylvester's equation and computing the matrix products are the most
expensive steps of the algorithms for large Hamiltonians.
Pymablock can efficiently construct an effective Hamiltonian of a small
subspace even when the full Hamiltonian is a sparse matrix that is too costly to
diagonalize.
It does so by avoiding explicit computation of operators in $B$ subspace, and by
utilizing the sparsity of the Hamiltonian to compute the Green's function.
To do so, Pymablock uses either the MUMPS sparse solver via the python-mumps
wrapper or the KPM method, an approach originally introduced in
\cite{Irfan_2019}.

To implement this, we use the matrix $\Psi_A$ of the eigenvectors of the $A$
subspace to rewrite the Hamiltonian as
%
\begin{align}
\mathcal{H} \to \begin{pmatrix}
\Psi_A^\dagger \mathcal{H} \Psi_A & \Psi_A^\dagger \mathcal{H} P_B \\
P_B \mathcal{H} \Psi_A & P_B \mathcal{H} P_B
\end{pmatrix},
\end{align}
%
where $P_B = 1 - \Psi_A \Psi_A^\dagger$ is the projector onto the $B$ subspace.
This Hamiltonian is larger in size than the original one because the $B$ block has
additional null vectors corresponding to the $A$ subspace.
This, however, allows to preserve the sparsity structure of the Hamiltonian by applying
$P_B$ and $\mathcal{H}$ separately.
Additionally, applying $P_B$ is efficient because $\Psi_A$ is a low rank matrix.
We then perform perturbation theory of the rewritten $\mathcal{H}$.

To solve the Sylvester's equation for the modified Hamiltonian, we write it for
every row of $V_n^{AB}$ separately:
%
\begin{align}
V_{n, ij}^{AB} (E_i - H_0) = Y_{n, j}
\end{align}
%
This equation is well-defined despite $E_i - H_0$ is not invertible because
$Y_{n}$ has no components in the $A$ subspace.
