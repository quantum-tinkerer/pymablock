\section{Pymablock's algorithm}

\subsection{Problem statement}

Pymablock finds a series of the unitary transformation $\mathcal{U}$ (we use
calligraphic letters to denote series) that block-diagonalizes the Hamiltonian
%
\begin{align}
\label{hamiltonian}
\mathcal{H} = H_0 + \mathcal{H}',\quad H_0 = \begin{pmatrix}
H_0^{AA} & 0\\
0 & H_0^{BB}
\end{pmatrix},
\end{align}
%
with $\mathcal{H}'$ containing an arbitrary number and orders of perturbations.
The series here may be multivariate, and they represent sums of the form
%
\begin{align}
\mathcal{A} = \sum_{n_1=0}^\infty \sum_{n_2=0}^\infty \cdots \sum_{n_k=0}^\infty \lambda_1^{n_1} \lambda_2^{n_2} \cdots \lambda_k^{n_k} A_{n_1, n_2, \ldots, n_k},
\end{align}
%
where $\lambda_i$ are the perturbation parameters and $A_{n_1, n_2, \ldots,
n_k}$ are linear operators.
%
The problem statement, therefore, is finding $\mathcal{U}$ and
$\tilde{\mathcal{H}}$ such that
%
\begin{align}
\label{eq:problem_definition}
\tilde{\mathcal{H}} = \mathcal{U}^\dagger \mathcal{H} \mathcal{U},\quad \tilde{\mathcal{H}}^{AB} = 0,\quad \mathcal{U}^\dagger \mathcal{U} = 1,
\end{align}
%
which is schematically shown in Fig.~\ref{fig:block_diagonalization}.
Series multiply according to the Cauchy product:
%
$$
\mathcal{C} = \mathcal{A}\mathcal{B} \Leftrightarrow C_\mathbf{n} = \sum_{\mathbf{m} + \mathbf{p} = \mathbf{n}} A_\mathbf{m} B_\mathbf{p}.
$$
%
The Cauchy product is the most expensive operation in perturbation theory,
because it involves a large number of multiplications between potentially large
matrices.
For example, evaluating $\mathbf{n}$-th order of $\mathcal{C}$ requires
$\sim\prod_i n_i \equiv N$ multiplications of the series elements.
A direct computation of all the possible index combinations in a product
between three series $\mathcal{A}\mathcal{B}\mathcal{C}$ would have a higher
cost $\sim N^2$, however if we use associativity of the product and compute
this as $(\mathcal{A}\mathcal{B})\mathcal{C}$, then the scaling of the cost
stays $\sim N$.
%
\begin{figure}[h!]
\centering
\includegraphics[width=\textwidth]{figures/diagrams_H.pdf}
\caption{
  Perturbative block-diagonalization of a gapped Hamiltonian with a first order
  perturbation.
  The effective Hamiltonian is the $2\times 2$ block in the top left corner in
  the last panel.
}
\label{fig:block_diagonalization}
\end{figure}

There are many ways to solve the problem~\eqref{eq:problem_definition} that
give identical expressions for $\mathcal{U}$ and $\tilde{\mathcal{H}}$.
We are searching for a procedure that satisfies two additional constraints:
%
\begin{itemize}
    \item It has the same complexity scaling as a Cauchy product.
    \item It does not require multiplications by $H_0$.
\end{itemize}
%
The second requirement is because in perturbation theory, $n$-th order  corrections to
$\tilde{\mathcal{H}}$ carry $n$ energy denominators $1/(E_i - E_j)$, where
$E_i$ and $E_j$ are the eigenvalues of $H_0$ belonging to different subspaces.
Therefore, any additional multiplications by $H_0$ must cancel with
additional energy denominators.
Multiplying by $H_0$ is therefore unnecessary work, and it gives longer
intermediate expressions.
The goal of our algorithm is thus to be efficient and to produce compact
results that do not require further simplifications.
\subsection{Existing solutions}
\co{Pymablock's algorithm does not use the Schrieffer--Wolff transformation,
because the former is inefficient.}
A common approach to construct effective Hamiltonians is to use the
Schrieffer--Wolff transformation~\cite{Schrieffer_1966}:
%
\begin{align}
\tilde{\mathcal{H}} = e^\mathcal{S} &\mathcal{H} e^{-\mathcal{S}}, \\
e^{\mathcal{S}} = 1 + \mathcal{S} + \frac{1}{2!} \mathcal{S} \mathcal{S}
+ &\frac{1}{3!} \mathcal{S} \mathcal{S} \mathcal{S} + \cdots,
\end{align}
%
where $\mathcal{S} = \sum_n S_n$ is an antihermitian polynomial series in the
perturbative parameter, making $e^\mathcal{S}$ a unitary transformation.
Requiring that $\tilde{\mathcal{H}}^{AB} = 0$ gives a recursive equation for
$S_n$, whose terms are nested commutators between the series of $\mathcal{S}$
and $\mathcal{H}$.
Similarly, the transformed Hamiltonian is given by a series of nested
commutators
%
\begin{equation}
\label{eq:SW_H}
\tilde{\mathcal{H}} = \sum_{j=0}^\infty \frac{1}{j!} \Big [\mathcal{H}, \sum_{n=0}^{\infty} S_n \Big ]^{(j)}.
\end{equation}
%
Regardless of the specific implementation, this expression does not meet either
of our two requirements:
\begin{itemize}
  \item The direct computation of the series elements requires a $\sim \exp N$
  multiplications, and even an optimized one has a $\sim N^2$ scaling.
  \item Evaluating Eq.~\eqref{eq:SW_H} contains multiplications by $H_0$.
\end{itemize}

\co{There are algorithms that use different parametrizations for U a
difference that is crucial for efficiency, even though the results are
equivalent.}
Alternative parametrizations of the unitary transformation $\mathcal{U}$
require solving unitarity and block diagonalization conditions too, but
give rise to a different recursive procedure for the series elements.
For example, using hyperbolic functions
%
\begin{gather}
\mathcal{U} = \cosh{\mathcal{G}} + \sinh{\mathcal{G}}, \quad
\mathcal{G} = \sum_{i=0}^{\infty} G_i,
\end{gather}
%
leads to different recursive expressions for $G_i$ \cite{Shavitt_1980},
but does not change the algorithm's complexity.
On the other hand, using a polynomial series directly
%
\begin{align}
\mathcal{U} &= \sum_{i=0}^{\infty} U_i,
\end{align}
%
gives rise to another recursive equation for $U_i$
\cite{Van_Vleck_1929, Lowdin_1962, Klein_1974, Suzuki_1983}.
Still, this choice results in an expression for $\tilde{\mathcal{H}}$ whose
terms include products by $H_0$, and therefore requires additional
simplifications.

\co{The existing algorithms with linear scaling are not suitable for the
construction of an effective Hamiltonian.}
Despite the conceptual equivalence of the algorithms and the agreement of their
results, there is a crucial difference in their computational efficiency: a
Schrieffer--Wolff transformation has an exponential scaling with the
perturbative order, but it can be reduced.
C. Bloch's perturbation theory \cite{Bloch_1958}, for example,
aims to find a similarity transform that brings the Hamiltonian to a
block-triangular form, losing its Hermiticity and orhogonality properties.
The iterative procedure to find the similarity transform requires computing
fewer expressions for the series elements than the Schrieffer-Wolff
transformation \cite{Bravyi_2011}, and the effective Hamiltonian is more
compact.
However, the algorithm is only useful to obtain the spectrum of the low energy
subspace, not its wavefunctions.
Reference \cite{Li_2022}, for example, introduces an
algorithm with linear scaling for diagonalization of a single state by
reformulating the recursive steps of the Schrieffer--Wolff transformation.
Block diagonalization of a Hamiltonian, however, recovers the exponential
scaling.
Another approach with linear scaling is that of density matrix perturbation
theory \cite{McWeeny_1962,McWeeny_1968,Truflandier_2020}, in which the
density matrix of a single-particle system is also a power series with
respect to a perturbative parameter:
%
\begin{align}
  \mathcal{D} = \sum_{i=0}^{\infty} D_i.
\end{align}
%
The elements of the series are found by solving two recursive conditions,
$\mathcal{D}^2 = \mathcal{D}$ and $[\mathcal{H}, \mathcal{D}]=0$.
This approach, however, does not provide an effective Hamiltonian, and even
though it has a linear scaling, it deals with the entire Hilbert space, not
only the low energy subspace.
We thus identify the need for an algorithm that combines linear scaling with
the ability to construct an effective Hamiltonian.

\subsection{Our solution}

To find $\mathcal{U}$, let us separate it into an identity and $\mathcal{U}' =
\mathcal{W} + \mathcal{V}$:
%
\begin{align}
\label{eq:U}
\mathcal{U} = 1 + \mathcal{U}' = 1 + \mathcal{W} + \mathcal{V},\quad \mathcal{W}^\dagger = \mathcal{W},\quad \mathcal{V}^\dagger = -\mathcal{V}.
\end{align}
%
First, we use the unitarity condition
$\mathcal{U}^\dagger \mathcal{U} = 1$ by substituting $\mathcal{U}'$ into it
and obtain
%
\begin{align}
\label{eq:W}
\mathcal{W} &= \frac{1}{2}(\mathcal{U}'^\dagger + \mathcal{U}') \nonumber \\
  &= \frac{1}{2} \Big[(1 + \mathcal{U}'^\dagger)(1+\mathcal{U}') - 1 - \mathcal{U}'^\dagger \mathcal{U}' \Big] \nonumber \\
  &= -\frac{1}{2} \mathcal{U}'^\dagger \mathcal{U}'.
\end{align}
%
Because $\mathcal{U}'$ has no $0$-th order term, $(\mathcal{U}'^\dagger
\mathcal{U}')_\mathbf{n}$ does not depend on the $\mathbf{n}$-th order of
$\mathcal{U}'$ nor $\mathcal{W}$.
More generally, a Cauchy product $\mathcal{A}\mathcal{B}$ where $\mathcal{A}$
and $\mathcal{B}$ have no $0$-th order terms depends on $\mathcal{A}_1, \ldots,
\mathcal{A}_{n-1}$ and $\mathcal{B}_1, \ldots, \mathcal{B}_{n-1}$.
This allows us to use Cauchy products to define recurrence relations, which
we apply throughout the algorithm.
Therefore, we compute $\mathcal{W}$ as a Cauchy product of $\mathcal{U}'$ with
itself \footnotemark[1].

\footnotetext[1]{
Using the definition of $\mathcal{W}$ as the Hermitian part of $\mathcal{U}'$,
and the unitarity condition:
%
$$
2\mathcal{W}
= \mathcal{U}' + \mathcal{U}'^\dagger
= -\mathcal{U}'^\dagger \mathcal{U}'
= -\mathcal{W}^2 + \mathcal{V}^2.
$$
%
we see that we could alternatively define $\mathcal{W}$ as a Taylor series in
$\mathcal{V}$:
%
$$
\mathcal{W} = \sqrt{1 + \mathcal{V}^2} - 1 \equiv f(\mathcal{V}) \equiv \sum_n a_n \mathcal{V}^{2n},
$$
%
however the scaling of such a Cauchy product becomes slower if we need to
compute a Taylor expansion of a series.
A direct computation of all possible products of terms would require $\sim \exp
N$ multiplications.
We improve on this by defining a new series as $\mathcal{A}^{n+1} =
\mathcal{A}\mathcal{A}^{n}$ and reusing the previously computed results, which
brings these costs down to $\sim N^2$.
Using the Taylor expansion approach is therefore both more complicated and more
computationally expensive than the recurrent definition in Eq.~\eqref{eq:W}.
}

To compute $\mathcal{U}'$ we also need to find $\mathcal{V}$, which is defined
by the requirement $\tilde{\mathcal{H}}^{AB} = 0$.
Additionally, we constrain $\mathcal{V}$ to be block off-diagonal:
$\mathcal{V}^{AA} = \mathcal{V}^{BB} = 0$,
so that the resulting unitary transformation is equivalent to the
Schrieffer--Wolff transformation.
In turn, this means that $\mathcal{W}$ is block-diagonal and that the norm
of $\mathcal{U}'$ is minimal.

\co{We find V and the transformed Hamiltonian.}
To find $\mathcal{V}$, we need to first look at the transformed Hamiltonian:
%
\begin{align}
\tilde{\mathcal{H}} = \mathcal{U}^\dagger \mathcal{H} \mathcal{U} = H_0 +
\mathcal{U}'^\dagger H_0 + H_0 \mathcal{U}' + \mathcal{U}'^\dagger H_0
\mathcal{U}' + \mathcal{U}^\dagger\mathcal{H'}\mathcal{U},
\end{align}
%
where we used $\mathcal{U}=1+\mathcal{U}'$ and $\mathcal{H} = H_0 +
\mathcal{H'}$.
Because we want to avoid unnecessary products by $H_0$, we need to get rid of
the terms that contain it by replacing them with an alternative expression.
Our strategy is to define an auxiliary operator $\mathcal{X}$ that we can
compute without ever multiplying by $H_0$.
Like $\mathcal{U}'$, $\mathcal{X}$ needs to be defined via a recurrence
relation, which we will find later.
Because the expression above has $H_0$ multiplied by $\mathcal{U}'$ by the left
and by the right, we get rid of these terms by making sure that $H_0$
multiplies terms from one side only.
To achieve this, we choose $\mathcal{X}=\mathcal{Y}+\mathcal{Z}$ to be the commutator between
$\mathcal{U}'$ and $H_0$:
%
\begin{align}
\label{eq:XYZ}
\mathcal{X} \equiv [\mathcal{U}', H_0] = \mathcal{Y} + \mathcal{Z}, \quad
\mathcal{Y} \equiv [\mathcal{V}, H_0] = \mathcal{Y}^\dagger,\quad
\mathcal{Z} \equiv [\mathcal{W}, H_0] = -\mathcal{Z}^\dagger,
\end{align}
%
where $\mathcal{Y}$ is therefore block off-diagonal and $\mathcal{Z}$, block
diagonal.
We use $H_0 \mathcal{U}' = \mathcal{U}' H_0 -\mathcal{X}$ to move $H_0$ through
to the right and find
%
\begin{align}
\label{eq:H_tilde}
  \tilde{\mathcal{H}}
  &= H_0 + \mathcal{U}'^\dagger H_0 + (H_0 \mathcal{U}') + \mathcal{U}'^\dagger H_0
  \mathcal{U}' + \mathcal{U}^\dagger(\mathcal{H'}\mathcal{U}) \nonumber
  \\
  &= H_0 + \mathcal{U}'^\dagger H_0 + \mathcal{U}'H_0 - \mathcal{X} + \mathcal{U}'^\dagger (\mathcal{U}' H_0 - \mathcal{X}) + \mathcal{U}^\dagger\mathcal{H'}\mathcal{U} \nonumber \\
  &= H_0 + (\mathcal{U}'^\dagger + \mathcal{U}' + \mathcal{U}'^\dagger \mathcal{U}')H_0 - \mathcal{X} - \mathcal{U}'^\dagger \mathcal{X} + \mathcal{U}^\dagger\mathcal{H'}\mathcal{U} \nonumber \\
  &= H_0 - \mathcal{X} - \mathcal{U}'^\dagger \mathcal{X} + \mathcal{U}^\dagger\mathcal{H'}\mathcal{U},
\end{align}
%
where the terms multiplied by $H_0$ cancel by unitarity.

\missingfigure{Show block structure of series.}

The transformed Hamiltonian does not contain products by $H_0$ anymore, but it
does depend on $\mathcal{X}$, an auxiliary operator whose recurrent definition
we do not know yet.
To find it, we first focus on its anti-Hermitian part, $\mathcal{Z}$.
Since recurrence relations are expressions whose right hand side contains
Cauchy products between series, we need to find a way to make a product appear.
We do so by using the unitarity condition $\mathcal{U}'^\dagger + \mathcal{U}' =
-\mathcal{U}'^\dagger \mathcal{U}'$ to rewrite $\mathcal{Z}$:
%
\begin{align}
\label{eq:Z}
\mathcal{Z}
&= \frac{1}{2} (\mathcal{X} - \mathcal{X}^{\dagger}) \nonumber \\
&= \frac{1}{2}\Big[ (\mathcal{U}' + \mathcal{U}'^{\dagger}) H_0 - H_0 (\mathcal{U}' + \mathcal{U}'^{\dagger}) \Big] \nonumber \\
&= \frac{1}{2} \Big[ - \mathcal{U}'^{\dagger} (\mathcal{U}'H_0 - H_0 \mathcal{U}') + (\mathcal{U}'H_0 - H_0 \mathcal{U}')^{\dagger} \mathcal{U}' \Big] \nonumber \\
&= \frac{1}{2} (-\mathcal{U}'^{\dagger} \mathcal{X} + \mathcal{X}^{\dagger} \mathcal{U}').
\end{align}
%
Similar to computing $W_{\mathbf{n}}$, computing $Z_{\mathbf{n}}$ requires lower orders of
$\mathcal{X}$ and $\mathcal{U}'$, all blocks included.
This defines a recursive relation for $\mathcal{Z}$.
Then, we compute the Hermitian part of $\mathcal{X}$ by requiring that
$\tilde{\mathcal{H}}^{AB} = 0$ and find
%
\begin{align}
\label{eq:Y}
\mathcal{X}^{AB} = (\mathcal{U}^\dagger \mathcal{H}' \mathcal{U} -
\mathcal{U}'^\dagger \mathcal{X})^{AB}.
\end{align}
%
Once again, despite $\mathcal{X}$ enters the right hand side, because all the
terms lack \nth{0} order, this defines a recursive relation for $\mathcal{X}^{AB}$,
and therefore $\mathcal{Y}$.

The final part is standard: the definition of $\mathcal{Y}$ in
Eq.~\eqref{eq:XYZ} fixes $\mathcal{V}$ as a solution of:
%
\begin{align}
\label{eq:sylvester}
\mathcal{V}^{AB}H_0^{BB} - H_0^{AA} \mathcal{V}^{AB} = \mathcal{Y}^{AB},
\end{align}
%
a Sylvester's equation, which we only need to solve once for every new order.
In the eigenbasis of $H_0$, the solution of Sylvester's equation is
$V^{AB}_{\mathbf{n}, ij} = Y^{AB}_{\mathbf{n}, ij}/(E_i - E_j)$, where $E_i$ are the eigenvalues of
$H_0$.
However, even if the eigenbasis of $H_0$ is not available, there are efficient
algorithms to solve Sylvester's equation, see below.

\subsection{Algorithm}

We now have the complete algorithm:
%
\begin{enumerate}
    \item Define series $\mathcal{U}'$ and $\mathcal{X}$ and make use of their block structure and Hermiticity.
    \item To define the diagonal blocks of $\mathcal{U}'$, use $\mathcal{W} = -\mathcal{U}'^\dagger\mathcal{U}'/2$.
    \item To find the off-diagonal blocks of $\mathcal{U}'$, solve Sylvester's equation $\mathcal{V}^{AB}H_0^{BB} - H_0^{AA}\mathcal{V}^{AB} = \mathcal{Y}^{AB}$.
      This requires $\mathcal{X}$.
    \item To find the diagonal blocks of $\mathcal{X}$, define $\mathcal{Z} = (-\mathcal{U}'^\dagger\mathcal{X} + \mathcal{X}^\dagger\mathcal{U}')/2$.
    \item For the off-diagonal blocks of $\mathcal{X}$, use $\mathcal{Y}^{AB} =
    (-\mathcal{U}'^\dagger\mathcal{X} +
     \mathcal{U}^\dagger\mathcal{H}'\mathcal{U})^{AB}$.
    \item  Compute the effective Hamiltonian as $\tilde{\mathcal{H}}_{\textrm{diag}} = H_0 - \mathcal{X} - \mathcal{U}'^\dagger \mathcal{X} + \mathcal{U}^\dagger\mathcal{H'}\mathcal{U}$.
\end{enumerate}

\subsection{Equivalence with Schrieffer--Wolff transformation}
\co{Our algorithm is equivalent to a Schrieffer--Wolff transformation}
Both the Pymablock algorithm and the more commonly used Schrieffer-Wolff
transformation find a unitary transformation $\mathcal{U}$ such that
$\tilde{\mathcal{H}}^{AB}=0$.
They are therefore equivalent up to a gauge choice in each subspace, $A$ and
$B$.

We establish the equivalence between the two by demonstrating that this gauge
choice is the same for both algorithms.
The Schrieffer--Wolff transformation uses $\mathcal{U} = \exp \mathcal{S}$,
where $\mathcal{S} = -\mathcal{S}^\dagger$ and $\mathcal{S}^{AA} =
\mathcal{S}^{BB} = 0$.
The series $\exp\mathcal{S}$ contains all possible products of $S_n$ of all
lengths with fractional prefactors.
For every term $S_{k_1}S_{k_2}\cdots S_{k_n}$, there is a corresponding term
$S_{k_n}S_{k_{n-1}}\cdots S_{k_1}$ with the same prefactor.
If the number of $S_{k_n}$ is even, then both terms are block-diagonal since
each $S_n$ is block off-diagonal.
Because $S_n$ are anti-Hermitian, the two terms are Hermitian conjugates of each
other, and therefore their sum is Hermitian.
On the other hand, if the number of $S_{k_n}$ is odd, then the two terms are
block off-diagonal and their sum is anti-Hermitian by the same reasoning.
Therefore, just like in our algorithm, the diagonal blocks of $\exp S$ are
Hermitian, while off-diagonal blocks are anti-Hermitian.
Schrieffer--Wolff transformation produces a unique answer and satisfies the same
diagonalization requirements as our algorithm, which means that the two produce
the same effective Hamiltonian.

\subsection{Extra optimization: common subexpression elimination}
%
We further optimize the algorithm by reusing products that are needed in several
places.
%
Firstly, we rewrite the expressions for $\mathcal{Z}$ and $\tilde{\mathcal{H}}$
by utilizing the Hermitian conjugate of $\mathcal{U}'^\dagger \mathcal{X}$ without recomputing it:
%
\begin{gather*}
\mathcal{Z} = \frac{1}{2}[(-\mathcal{U}'^\dagger \mathcal{X})- \textrm{h.c.}],\\
\tilde{\mathcal{H}} = H_0 + \mathcal{U}^\dagger \mathcal{H}' \mathcal{U} - (\mathcal{U}'^\dagger \mathcal{X} + \textrm{h.c.}),
\end{gather*}
%
where $\textrm{h.c.}$ is the Hermitian conjugate, and $\mathcal{X}$ drops out from the diagonal blocks of $\tilde{\mathcal{H}}$ because diagonal of $\mathcal{X}$ is anti-Hermitian.
%
To compute $\mathcal{U}^\dagger \mathcal{H}' \mathcal{U}$ faster, we express it
using $\mathcal{F} \equiv \mathcal{H}'\mathcal{U}'$:
%
$$
\mathcal{U}^\dagger \mathcal{H}' \mathcal{U} = \mathcal{H}' + \mathcal{F} + \mathcal{F}^\dagger + \mathcal{U}'^\dagger \mathcal{F}.
$$
%
To further optimize the computations, we observe that some products appear both in $\mathcal{U}'^\dagger \mathcal{X}$ and $\mathcal{U}^\dagger \mathcal{H}' \mathcal{U}$.
%
To reuse these products, we separate the perturbation into diagonal and off-diagonal parts $\mathcal{H}' = \mathcal{H}'_\textrm{diag} + \mathcal{H}'_\textrm{offdiag}$.
%
We then introduce variables
%
\begin{align}
\mathcal{A} = \mathcal{H}'_\textrm{diag} \mathcal{U}', \quad
\mathcal{B} = \mathcal{H}'_\textrm{offdiag} \mathcal{U}', \quad
\mathcal{C} = \mathcal{X} - \mathcal{H}'_\textrm{offdiag}
\end{align}
%
This gives an updated expression for $\mathcal{Z}$:
%
\begin{align}
\label{eq:Z_optimized}
\mathcal{Z} = \frac{1}{2}(\mathcal{B}^\dagger - \mathcal{U}^\dagger\mathcal{C}) - \textrm{h.c.},
\end{align}
%
and more importantly for $\tilde{\mathcal{H}}$:
%
\begin{align}
\label{eq:H_tilde_optimized}
\tilde{\mathcal{H}} = H_0 + \mathcal{A} + \mathcal{A}^\dagger + (\mathcal{B} + \mathcal{B}^\dagger)/2 + \mathcal{U}'^\dagger (\mathcal{A} + \mathcal{B}) - (\mathcal{U}^\dagger \mathcal{C} + \textrm{h.c.})/2.
\end{align}
